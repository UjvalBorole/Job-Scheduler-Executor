# docker network create backend
# docker-compose -f infra.yml pull && docker-compose -f infra.yml up -d
name: 'Infrastructure Services'
services:
  # =========================
  # MongoDB Database  
  # =========================

  mongodb:
    image: mongo:6
    container_name: mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
      MONGO_INITDB_DATABASE: job_scheduler_db
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD-SHELL", "mongosh --quiet --username root --password root --eval 'db.adminCommand(\"ping\").ok' | grep 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 500m
    networks:
      - backend


  # =========================
  # Postgres Database & pgAdmin     
  # =========================

  postgres:
    container_name: postgres_container #this is the host name
    image: postgres:14
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
      POSTGRES_DB: JobDB
    volumes:
      - postgres:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U root -d JobDB"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 500m
    restart: unless-stopped

   # =========================
   # pgAdmin  
    # ========================= 

  pgadmin:
    container_name: pgadmin_container
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-pgadmin4@pgadmin.org}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
    volumes:
      - pgadmin:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 500m
    restart: unless-stopped


  # =========================
  # Kafka Broker (KRaft mode) 
  # =========================

  # kafka:
  #   image: bitnami/kafka:3.6.2
  #   container_name: kafka
  #   ports:
  #     - "9092:9092"
  #     - "29092:29092"
  #   environment:
  #     # KRaft Configuration
  #     KAFKA_CFG_PROCESS_ROLES: "controller,broker"
  #     KAFKA_CFG_NODE_ID: "1"
  #     KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
  #     KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      
  #     # Corrected Listeners Configuration
  #     KAFKA_CFG_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092"
  #     KAFKA_CFG_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
  #     KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      
  #     # Cluster ID
  #     KAFKA_KRAFT_CLUSTER_ID: "AAAAAAAAAAAAAAAAAAAAAQ"
      
  #     # Storage
  #     KAFKA_CFG_LOG_DIRS: "/bitnami/kafka/data"
      
  #     # Other Settings
  #     ALLOW_PLAINTEXT_LISTENER: "yes"
  #     KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"

  #   volumes:
  #     - kafka_data:/bitnami/kafka
  #   networks:
  #     - backend
  #   healthcheck:
  #     test: ["CMD-SHELL", "kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 0"]
  #     interval: 20s
  #     timeout: 30s
  #     retries: 10
  #     start_period: 120s
  #   restart: unless-stopped

  # kafka:
  #   # image: bitnami/kafka:3.6
  #   image: apache/kafka:3.7.0
  #   # image: confluentinc/cp-kafka
  #   # image: bitnami/kafka:3.7.0-debian-12-r0
  #   # image: ghcr.io/bitnami/kafka:3.8.0
  #   # image: quay.io/strimzi/kafka:0.40.0-kafka-3.7.0
  #   container_name: kafka
  #   ports:
  #     - "9092:9092"
  #     - "29092:29092"
  #   environment:
  #     # KRaft Configuration
  #     KAFKA_CFG_PROCESS_ROLES: "controller,broker"
  #     KAFKA_CFG_NODE_ID: "1"
  #     KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
  #     KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      
  #     # Listeners Configuration
  #     KAFKA_CFG_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092"
  #     KAFKA_CFG_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
  #     KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      
  #     # Cluster ID
  #     KAFKA_KRAFT_CLUSTER_ID: "AAAAAAAAAAAAAAAAAAAAAQ"
      
  #     # Storage
  #     KAFKA_CFG_LOG_DIRS: "/bitnami/kafka/data"
      
  #     # Other Settings
  #     ALLOW_PLAINTEXT_LISTENER: "yes"
  #     KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"

  #   volumes:
  #     - kafka_data:/bitnami/kafka
  #   networks:
  #     - backend
  #   healthcheck:
  #     test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 0"]
  #     interval: 20s
  #     timeout: 30s
  #     retries: 10
  #     start_period: 120s
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 500m
  #   restart: unless-stopped

  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      # KRaft mode
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # Listeners
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"

      # Cluster ID (must be a valid Base64 string, you can generate one via `./kafka-storage.sh random-uuid`)
      KAFKA_CLUSTER_ID: "AAAAAAAAAAAAAAAAAAAAAQ"

      # Storage dir
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

      # Other
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 0"]
      interval: 20s
      timeout: 30s
      retries: 10
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 500m
    restart: unless-stopped


  # =========================
  # Redis Cache  
  # =========================

  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
    - redis-data:/data
    environment:
    # - SPRING_REDIS_HOST=redis
    - SPRING_REDIS_PORT=6379
    - SPRING_REDIS_TIMEOUT=5000ms
    - SPRING_REDIS_LETTUCE_POOL_MAX_ACTIVE=8
    - SPRING_REDIS_LETTUCE_POOL_MAX_WAIT=5000ms
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 500m
    restart: unless-stopped



  # mailhog:
  #   image: mailhog/mailhog:v1.0.1
  #   container_name: mailhog
  #   ports:
  #     - "1025:1025"
  #     - "8025:8025"

  # keycloak:
  #   image: quay.io/keycloak/keycloak:26.3.0
  #   command: [ 'start-dev', '--import-realm', '--http-port=9191' ]
  #   container_name: keycloak
  #   hostname: keycloak
  #   volumes:
  #     - ./realm-config:/opt/keycloak/data/import
  #   environment:
  #     - KEYCLOAK_ADMIN=admin
  #     - KEYCLOAK_ADMIN_PASSWORD=admin1234
  #   ports:
  #     - "9191:9191"
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 2gb

volumes:
  postgres:
  pgadmin:
  kafka_data:
  redis-data:
  mongo-data:
  # shared-uploads:

networks:
  backend:
    external: true


